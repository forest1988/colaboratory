{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prophetnet_seq2seqtrainer.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ZHMn_DxzU_EL"
      ],
      "authorship_tag": "ABX9TyMPAXVPI3SGeNg4FoF7lo9p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/forest1988/colaboratory/blob/main/prophetnet_seq2seqtrainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ond9VTc5Zt8d"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQpqDmBWaESu",
        "outputId": "9fa398e8-867e-45cc-f585-480084da0c85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.7.0+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzxYczZ0aF97",
        "outputId": "f84ed631-1659-4eb0-848a-69322afcc8ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers.git\n",
        "#git clone https://github.com/forest1988/transformers.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'transformers' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9khHo2A9b1p5",
        "outputId": "dee00d4b-2951-41f7-a27a-db999d59068e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd transformers/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8aOcq_2RJDV",
        "outputId": "0fce6954-353a-4622-e20c-30472f791ae1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -e ."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (20.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.7)\n",
            "Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.9.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.0.43)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.1.91)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.4.0) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.4.0) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (2020.6.20)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.4.0) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.4.0) (50.3.2)\n",
            "Installing collected packages: transformers\n",
            "  Found existing installation: transformers 3.4.0\n",
            "    Can't uninstall 'transformers'. No files were found to uninstall.\n",
            "  Running setup.py develop for transformers\n",
            "Successfully installed transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wpt5LV-MMlG",
        "outputId": "4aa96a27-9e2a-413e-98aa-a24b98d75a46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/transformers/examples/seq2seq/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/transformers/examples/seq2seq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKqwk3OnZZfr",
        "outputId": "2269b1e1-c032-4f67-ae90-718ea94a356d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# to avoid the \"ModuleNotFoundError\" \n",
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append('/content/transformers/src')\n",
        "print(sys.path)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/content/transformers_modified/src', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython']\n",
            "['', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/content/transformers_modified/src', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython', '/content/transformers/src']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmKBOl0cg7yK"
      },
      "source": [
        "# If \"ModuleNotFoundError\" occurs in this cell, please re-run the runtime. \n",
        "# (The first time Colab runtime runs, it seems the sys.path is not correctly updated when we use `pip install -e .`)\n",
        "\n",
        "import transformers"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iK_fsLQg_dP",
        "outputId": "66668dfa-d44f-46df-f30b-4a0d96337c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "transformers.__version__"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3.4.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iawDc5qpcSpj"
      },
      "source": [
        "## dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwGCB7HucRhf",
        "outputId": "2f8c05b4-dcac-4072-c363-9586a216886a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://cdn-datasets.huggingface.co/summarization/xsum.tar.gz\n",
        "!tar -xzvf xsum.tar.gz\n",
        "# !export XSUM_DIR=${PWD}/xsum\n",
        "# %env XSUM_DIR=${PWD}/xsum"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-05 17:52:07--  https://cdn-datasets.huggingface.co/summarization/xsum.tar.gz\n",
            "Resolving cdn-datasets.huggingface.co (cdn-datasets.huggingface.co)... 99.86.34.36, 99.86.34.88, 99.86.34.110, ...\n",
            "Connecting to cdn-datasets.huggingface.co (cdn-datasets.huggingface.co)|99.86.34.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 204844092 (195M) [application/x-tar]\n",
            "Saving to: ‘xsum.tar.gz.1’\n",
            "\n",
            "xsum.tar.gz.1       100%[===================>] 195.35M   102MB/s    in 1.9s    \n",
            "\n",
            "2020-11-05 17:52:09 (102 MB/s) - ‘xsum.tar.gz.1’ saved [204844092/204844092]\n",
            "\n",
            "xsum/\n",
            "xsum/train.target\n",
            "xsum/train.source\n",
            "xsum/val.source\n",
            "xsum/val.target\n",
            "xsum/test.source\n",
            "xsum/test.target\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlDoDzJMfVQy"
      },
      "source": [
        "import os\n",
        "os.environ['XSUM_DIR']=os.path.join(os.getcwd(), 'xsum')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqUue_HQgFQt",
        "outputId": "5eb13324-eb91-404c-9a9b-48ca3d7cc323",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!echo $XSUM_DIR"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/transformers/examples/seq2seq/xsum\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtDHrviaNM7R",
        "outputId": "ac1b988b-b4a2-469c-b082-f42dec93fd40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls $XSUM_DIR"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test.source  test.target  train.source\ttrain.target  val.source  val.target\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8WqDU4YdJlu"
      },
      "source": [
        "### Run BART-base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryygCHtEdXdY"
      },
      "source": [
        "%%capture\n",
        "!pip install gitpython\n",
        "!pip install rouge_score\n",
        "!pip install sacrebleu"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9-NwSpEaKlZ",
        "outputId": "99291214-8995-4184-f47c-7608115044c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python finetune_trainer.py \\\n",
        "    --learning_rate=3e-5 \\\n",
        "    --do_train --do_eval --evaluate_during_training \\\n",
        "    --predict_with_generate \\\n",
        "    --n_train 300 \\\n",
        "    --n_val 10 \\\n",
        "    --model_name_or_path facebook/bart-base \\\n",
        "    --data_dir $XSUM_DIR \\\n",
        "    --output_dir bart-base-tmp \\\n",
        "    --overwrite_output_dir "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-05 17:52:28.015292: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/content/transformers/src/transformers/training_args.py:347: FutureWarning: The `evaluate_during_training` argument is deprecated in favor of `evaluation_strategy` (which has more options)\n",
            "  FutureWarning,\n",
            "11/05/2020 17:52:30 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n",
            "11/05/2020 17:52:30 - INFO - __main__ -   Training/evaluation parameters Seq2SeqTrainingArguments(output_dir='bart-base-tmp', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=True, evaluation_strategy=<EvaluationStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=3e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Nov05_17-52-30_052fcbd2b9cb', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='bart-base-tmp', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, label_smoothing=0.0, sortish_sampler=False, predict_with_generate=True, adafactor=False, encoder_layerdrop=None, decoder_layerdrop=None, dropout=None, attention_dropout=None, lr_scheduler='linear')\n",
            "11/05/2020 17:52:47 - INFO - utils -   using task specific params for summarization: {'length_penalty': 1.0, 'max_length': 128, 'min_length': 12, 'num_beams': 4}\n",
            "  0% 0/114 [00:00<?, ?it/s]^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSEDjh1cbVm7",
        "outputId": "097f40e6-ff2f-43a8-af8c-a51a07382a62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40hjr62hgfSi"
      },
      "source": [
        "## Run with ProphetNet (Error occurs) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeRujgRxgeiB"
      },
      "source": [
        "from transformers import ProphetNetTokenizer, ProphetNetForConditionalGeneration #, ProphetNetForCausalLM\n",
        "\n",
        "# --- commeented out to avoid CUDA memory error --- \n",
        "\n",
        "# tokenizer = ProphetNetTokenizer.from_pretrained('microsoft/prophetnet-large-uncased')\n",
        "# model = ProphetNetForConditionalGeneration.from_pretrained('microsoft/prophetnet-large-uncased')\n",
        "\n",
        "# input_ids = tokenizer(\"Studies have been shown that owning a dog is good for you\", return_tensors=\"pt\").input_ids  # Batch size 1\n",
        "# decoder_input_ids = tokenizer(\"Studies show that\", return_tensors=\"pt\").input_ids  # Batch size 1\n",
        "# outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids, return_dict=True)\n",
        "\n",
        "# logits_next_token = outputs.logits  # logits to predict next token as usual\n",
        "# logits_ngram_next_tokens = outputs.logits_ngram  # logits to predict 2nd, 3rd, ... next tokens"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZIGb-UmTepq"
      },
      "source": [
        "# test how tokeinzer.decoder works \n",
        "\n",
        "# print(tokenizer.decode(input_ids[0]))\n",
        "# print(tokenizer.decode(input_ids[0], skip_special_tokens=True))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmcaKYecSBXW"
      },
      "source": [
        "# show the style of the output\n",
        "\n",
        "# print(type(outputs))\n",
        "# outputs.keys()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ol7nMTdSmrU"
      },
      "source": [
        "# outputs.logits.shape, outputs.logits_ngram.shape"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6Be8gaxS6_Z"
      },
      "source": [
        "# out_generate = model.generate(input_ids, num_beams=4, max_length=20, early_stopping=True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsG1KABATFBY"
      },
      "source": [
        "# out_generate.shape, out_generate[0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwKTqbERTJG4"
      },
      "source": [
        "# tokenizer.decode(out_generate.shape[0], skip_special_tokens=True)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJB3GanOfF0N",
        "outputId": "e33d5ca1-c356-41bd-feaa-2e5397f69f6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python finetune_trainer.py \\\n",
        "    --learning_rate=3e-5 \\\n",
        "    --do_train --do_eval --evaluate_during_training \\\n",
        "    --predict_with_generate \\\n",
        "    --n_train 100 \\\n",
        "    --n_val 10 \\\n",
        "    --model_name_or_path microsoft/prophetnet-large-uncased \\\n",
        "    --data_dir $XSUM_DIR \\\n",
        "    --output_dir tmp \\\n",
        "    --overwrite_output_dir"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-05 17:53:24.056751: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/content/transformers/src/transformers/training_args.py:347: FutureWarning: The `evaluate_during_training` argument is deprecated in favor of `evaluation_strategy` (which has more options)\n",
            "  FutureWarning,\n",
            "11/05/2020 17:53:31 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n",
            "11/05/2020 17:53:31 - INFO - __main__ -   Training/evaluation parameters Seq2SeqTrainingArguments(output_dir='tmp', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=True, evaluation_strategy=<EvaluationStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=3e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Nov05_17-53-31_052fcbd2b9cb', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='tmp', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, label_smoothing=0.0, sortish_sampler=False, predict_with_generate=True, adafactor=False, encoder_layerdrop=None, decoder_layerdrop=None, dropout=None, attention_dropout=None, lr_scheduler='linear')\n",
            "11/05/2020 17:54:19 - INFO - utils -   using task specific params for summarization: {'early_stopping': True, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'num_beams': 4}\n",
            "  0% 0/39 [00:00<?, ?it/s]Traceback (most recent call last):\n",
            "  File \"finetune_trainer.py\", line 303, in <module>\n",
            "    main()\n",
            "  File \"finetune_trainer.py\", line 248, in main\n",
            "    model_path=model_args.model_name_or_path if os.path.isdir(model_args.model_name_or_path) else None\n",
            "  File \"/content/transformers/src/transformers/trainer.py\", line 757, in train\n",
            "    for step, inputs in enumerate(epoch_iterator):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 435, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 475, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n",
            "    return self.collate_fn(data)\n",
            "  File \"/content/transformers/examples/seq2seq/utils.py\", line 280, in __call__\n",
            "    batch = self._encode(batch)\n",
            "  File \"/content/transformers/examples/seq2seq/utils.py\", line 322, in _encode\n",
            "    **self.dataset_kwargs,\n",
            "  File \"/content/transformers/src/transformers/tokenization_utils.py\", line 835, in prepare_seq2seq_batch\n",
            "    \"If your model requires more than input_ids for a typical forward pass, you should implement this method. \"\n",
            "NotImplementedError: If your model requires more than input_ids for a typical forward pass, you should implement this method. Returned keys should be [input_ids, attention_mask, labels]. See MarianTokenizer or T5Tokenizer for a reference implementation.\n",
            "  0% 0/39 [00:01<?, ?it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHMn_DxzU_EL"
      },
      "source": [
        "### Refer to T5Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_u3k1GCVo1Z"
      },
      "source": [
        "``` python\n",
        "    @add_start_docstrings(PREPARE_SEQ2SEQ_BATCH_DOCSTRING)\n",
        "    def prepare_seq2seq_batch(\n",
        "        self,\n",
        "        src_texts: List[str],\n",
        "        tgt_texts: Optional[List[str]] = None,\n",
        "        max_length: Optional[int] = None,\n",
        "        max_target_length: Optional[int] = None,\n",
        "        padding: str = \"longest\",\n",
        "        return_tensors: str = None,\n",
        "        truncation: bool = True,\n",
        "        **kwargs,\n",
        "    ) -> BatchEncoding:\n",
        "        if max_length is None:\n",
        "            max_length = self.max_len\n",
        "        model_inputs = self(\n",
        "            src_texts,\n",
        "            add_special_tokens=True,\n",
        "            return_tensors=return_tensors,\n",
        "            max_length=max_length,\n",
        "            padding=padding,\n",
        "            truncation=truncation,\n",
        "            **kwargs,\n",
        "        )\n",
        "        if tgt_texts is None:\n",
        "            return model_inputs\n",
        "        # Process tgt_texts\n",
        "        if max_target_length is None:\n",
        "            max_target_length = max_length\n",
        "        labels_and_decoder_mask = self(\n",
        "            tgt_texts,\n",
        "            add_special_tokens=True,\n",
        "            return_tensors=return_tensors,\n",
        "            padding=padding,\n",
        "            max_length=max_target_length,\n",
        "            truncation=truncation,\n",
        "            **kwargs,\n",
        "        )\n",
        "        model_inputs[\"labels\"] = labels_and_decoder_mask[\"input_ids\"]\n",
        "        return model_inputs\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Me6KG7SbSz5"
      },
      "source": [
        "## Try modified version of ProphetNet Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weFcd1mtVkTS",
        "outputId": "1160a832-c787-4be3-bad2-cbf68bad2783",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNO39XpFY7KB",
        "outputId": "5b77f057-0d34-4a69-a906-82467d24c296",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data  transformers  transformers_modified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljE2NiA-boRJ",
        "outputId": "b468f5d7-6303-456d-baee-da120444de9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import shutil\n",
        "\n",
        "if os.path.exists(\"transformers_modified\"):\n",
        "  print(\"The repository is already cloned. Remove and re-clone it.\")\n",
        "  shutil.rmtree(\"transformers_modified\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The repository is already cloned. Remove and re-clone it.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKRkCX1_Y7xl",
        "outputId": "667a1028-b5ea-41a8-d85a-b5e054a3247b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone -b forest1988-prophetnet-prepare-seq2seq-batch https://github.com/forest1988/transformers.git transformers_modified"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers_modified'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 49007 (delta 8), reused 8 (delta 3), pack-reused 48988\u001b[K\n",
            "Receiving objects: 100% (49007/49007), 36.38 MiB | 26.61 MiB/s, done.\n",
            "Resolving deltas: 100% (34170/34170), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_Jck3hWZIcE",
        "outputId": "d730a67f-ce1f-4145-c45f-84b7e0915ea2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd transformers_modified/"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/transformers_modified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNcmGGvSZi1V",
        "outputId": "e33110fb-86d0-40e6-ec33-fbef95b0f22b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -e . --upgrade"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/transformers_modified\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied, skipping upgrade: tokenizers==0.9.2 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.9.2)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.0.43)\n",
            "Requirement already satisfied, skipping upgrade: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.1.91)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.4.0) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.4.0) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.4.0) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.4.0) (0.17.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.4.0) (50.3.2)\n",
            "Installing collected packages: transformers\n",
            "  Found existing installation: transformers 3.4.0\n",
            "    Can't uninstall 'transformers'. No files were found to uninstall.\n",
            "  Running setup.py develop for transformers\n",
            "Successfully installed transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7t_HQtdZnMQ",
        "outputId": "c8d00bd4-7943-456a-e9fa-f61cc2bcd05a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/transformers_modified/examples/seq2seq/\n",
        "\n",
        "# Use already downloaded XSUM in /content/transformers/examples/seq2seq/xsum/"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/transformers_modified/examples/seq2seq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTUypp1QaKNM",
        "outputId": "0d8c1e76-faea-4afe-af66-225419546b15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!CUDA_LAUNCH_BLOCKING=1 python finetune_trainer.py \\\n",
        "    --learning_rate=3e-5 \\\n",
        "    --do_train --do_eval --evaluate_during_training \\\n",
        "    --max_source_length 20 \\\n",
        "    --max_target_length 20 \\\n",
        "    --predict_with_generate \\\n",
        "    --n_train 100 \\\n",
        "    --n_val 10 \\\n",
        "    --model_name_or_path microsoft/prophetnet-large-uncased \\\n",
        "    --data_dir $XSUM_DIR \\\n",
        "    --output_dir tmp \\\n",
        "    --overwrite_output_dir"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-05 17:59:56.159587: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/content/transformers_modified/src/transformers/training_args.py:347: FutureWarning: The `evaluate_during_training` argument is deprecated in favor of `evaluation_strategy` (which has more options)\n",
            "  FutureWarning,\n",
            "11/05/2020 17:59:58 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n",
            "11/05/2020 17:59:58 - INFO - __main__ -   Training/evaluation parameters Seq2SeqTrainingArguments(output_dir='tmp', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=True, evaluation_strategy=<EvaluationStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=3e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Nov05_17-59-58_052fcbd2b9cb', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='tmp', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, label_smoothing=0.0, sortish_sampler=False, predict_with_generate=True, adafactor=False, encoder_layerdrop=None, decoder_layerdrop=None, dropout=None, attention_dropout=None, lr_scheduler='linear')\n",
            "11/05/2020 18:00:18 - INFO - utils -   using task specific params for summarization: {'early_stopping': True, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'num_beams': 4}\n",
            "{'epoch': 3.0}\n",
            "100% 39/39 [10:21<00:00, 15.94s/it]\n",
            "11/05/2020 18:10:54 - INFO - __main__ -   *** Evaluate ***\n",
            "100% 2/2 [00:11<00:00,  5.51s/it]\n",
            "11/05/2020 18:11:35 - INFO - __main__ -   ***** Eval results *****\n",
            "11/05/2020 18:11:35 - INFO - __main__ -     eval_loss = 3.668583393096924\n",
            "11/05/2020 18:11:35 - INFO - __main__ -     eval_rouge1 = 11.818\n",
            "11/05/2020 18:11:35 - INFO - __main__ -     eval_rouge2 = 1.1429\n",
            "11/05/2020 18:11:35 - INFO - __main__ -     eval_rougeL = 10.6169\n",
            "11/05/2020 18:11:35 - INFO - __main__ -     eval_rougeLsum = 10.6734\n",
            "11/05/2020 18:11:35 - INFO - __main__ -     eval_gen_len = 24.9\n",
            "11/05/2020 18:11:35 - INFO - __main__ -     epoch = 3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdzsW-gLjgja"
      },
      "source": [
        "The warning messages saying `Keyword arguments {'add_prefix_space': False} not recognized.` are relevant to the pull requests below?\n",
        "\n",
        "- https://github.com/huggingface/transformers/pull/7470\n",
        "- https://github.com/huggingface/transformers/pull/8329"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_if9LKdPV1x"
      },
      "source": [
        ""
      ],
      "execution_count": 32,
      "outputs": []
    }
  ]
}